# ğŸ¤– MINKI â€” Minimal Input Natural Kinetic Interpreter

MINKI is an AI-powered compact IoT device designed to bridge the communication gap for the speech and hearing impaired. It translates sign language into real-time **text** and **speech**, while also assisting the **visually impaired** by detecting objects in their surroundings using computer vision.

---

## ğŸ¯ Problem Statement

Inaccessibility in communication restricts the personal and social lives of individuals with speech or hearing disabilities. MINKI aims to solve this by enabling intuitive, real-time, and voice-enabled sign language interpretation â€” giving people their voice back.

---

## ğŸš€ Features

- ğŸ–ï¸ **Sign Language to Text & Speech**: Real-time conversion of ASL (and other sign languages) to text and spoken words.
- ğŸ§  **AI-Powered Gesture Recognition**: Built using CNN-based models for accurate hand gesture classification.
- ğŸ§³ **Compact IoT Hardware**: Built on Raspberry Pi with minimal components to ensure portability.
- ğŸ¦¯ **Object Detection for the Visually Impaired**: Uses computer vision to detect surroundings and speak out nearby objects.
- ğŸ”Š **Offline & Real-time Support**: Works without the internet for edge-based instant responses.
- ğŸ“¦ **Future Ready**: Designed to be converted into a single compact PCB for mass production.

---

## ğŸ’¡ Tech Stack

### ğŸ§  AI & ML
- Python
- TensorFlow / PyTorch
- OpenCV
- MediaPipe

### ğŸ§° Hardware
- Raspberry Pi 4
- Pi Camera Module v2
- OLED Display (SSD1306)
- Micro Speaker + Audio Amp
- Battery Module (LiPo or USB-C)
- 3D-printed Enclosure (Optional)

### ğŸ›ï¸ Tools
- Figma (for UX planning)
- RPi.GPIO / smbus (for I2C communication)
- gTTS / espeak (Text-to-Speech)

---

## ğŸ“¸ Demo

https://user-demo-link-here.com

---

## ğŸ§ª Installation

### Clone the Repository
```bash
git clone https://github.com/TeamHadnt/MINKI.git
cd MINKI
